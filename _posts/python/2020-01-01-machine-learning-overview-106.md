---
layout: post
title:  第106天：机器学习概览
category: python
copyright: python
---

# 机器学习概览

近年来，随着人工智能热潮的席卷，“机器学习”、“深度学习”、“强化学习”等等层出不穷的概念、术语纷纷扰扰，不绝于耳；但是对大多数并不从事相关行业的人来说，就始终有一种雾里看花、似是而非的感觉。

正巧，Python 作为一门简单易用、功能强大的编程语言，在 AI 时代与人工智能相关的技术紧密结合，在这系列的 Python 交流中，我们就来大概地了解一下“机器学习到底是什么、可以干什么、应该怎么干”。

本篇仅作粗糙了解之用，不涉及具体的数学原理。更深入的了解可以查看参考资料。

<!--more-->

## 1. 算法和“算法”

首先我们要区别的一个概念就是常说的“算法”。

在我们学习编程的过程中，肯定会经常听到的一个说法就是“数据结构 + 算法 = 程序”；而当我们学习人工智能相关的内容时，也一直会听到 K 近邻算法、模拟退火算法等等术语。但是要注意一下，我们在平常的编程中用到的算法，是一种组织行为艺术，让恰当的人去做恰当的事；而在人工智能领域提到算法，没有特殊说明的情况下都是特指“人工智能算法”，这其实更像是一种暴力美学，不管三七二十一就是莽，不断试错，总要搞出一个结果，是一种具体的计算方法。

从数学分野上来讲，前者更多的是离散数学的内容，而后者更多的则是微积分和概率统计的内容。一般来说也很少混用这两个概念；若要混用，一般也会特意指明后者是“人工智能算法”或“机器学习算法”。

当然，实际上两种算法都符合“算法”的定义，即都是用来求解/解决问题的具体方法。但出于惯用法的考虑，我认为还是应当聊作区分，尤其是对于没有接触过一般算法的同学而言，更显必要。

## 2. 机器学习

人工智能的概念十分宽泛，流派众多，机器学习仅仅是其中一个分支；之所以我们经常听到的是“机器学习”而很少听到别的名字，主要是因为在当前这波大潮中，机器学习取得了压倒性的优势，相对其他流派性能更好、使用更方便、门槛更低，因此可能会造成一种“机器学习 = 人工智能”的错觉。

实际上我们经常说的机器学习是一种基于统计学方法的人工智能实现，我们也可以称其为“统计学习”——记得当时第一次看到李航老师的《统计学习方法》，我还真以为是讲如何学习统计学的书哈哈。

机器学习的“原材料”是各种各样的数据，称为“训练数据”，而机器学习的目的就是从这些数据中抽象出一些通用的规律/经验，获取一些难以被人类直观发现的现象/特征，用来在新的数据上取得正确的判断。对于给定的数据，机器学习模型得到的结果即是该模型的输出。

## 3. 机器学习的分类

机器学习总脱不开“将数据传递给机器 -> 机器从数据中学到规律/经验”这么一个流程，我们可以按照前一个步骤的特征的分类机器学习，也可以按照后一个步骤来进行分类。

### 3.1 基本分类

按照呈现给机器的数据的不同，机器学习可以粗略地分为**监督学习**（supervised learning）和**非监督学习**（unsupervised learning）两大类，此外有时也会分出强化学习、半监督学习等类别。

#### 3.1.1 监督学习

所谓监督学习，简单地讲就是目标明确、有奔头的机器学习过程。

从呈现给机器的数据的角度来讲，监督学习给出的训练数据就是带有明确指向的，称之为“标记过的数据”。也就是说我们完全清楚，某一个具体的数据实例，想要得到的对应输出结果是什么样的，并且我们也要求机器的输出结果不断地向我们预期的标记靠拢，这个“标记”就被称为“预期输出”，而机器实实在在的输出结果即为“实际输出”。

因此监督学习的工作，实际上就是在合理区间，力求将预期输出和实际输出之间的差值降到最小。

典型的问题包括数据分类和回归分析。

#### 3.1.2 非监督学习

对应于监督学习，顾名思义，非监督学习就是没有人“监督”的机器学习过程。所谓“监督”，其实就是说的训练数据实例带有的“标记”。

在监督学习中，机器学习的结果始终受到预期输出的约束，每一次结果都需要接受预期输出的评判；而非监督学习则不然。

非要打比方的话，监督学习就是应试教育，非监督学习更像是素质教育——啊当然，此处并不对应试教育和素质教育抱有任何预设立场，对监督学习和非监督学习更是如此，二者并无高下之别，仅仅是适用情境不同，仅此而已。

非监督学习允许模型自由发挥，“在阳光下自由生长”，具体长成什么样儿我们并不能掌控，我们也并不对学习的结果有太多的明确的预期。非监督学习更多的适用情形是发掘数据中一些隐藏的、通过简单分析难以察觉的特性。

典型的问题包括聚类问题。

### 3.2 按问题分类

机器学习按照具体的问题，大概可以分为这么几类：数据分类，回归分析，聚类问题。

#### 3.2.1 数据分类

数据分类应该是最常见的机器学习问题了，最典型的例子就是垃圾邮件的判别（啊，这个例子好像都举烂了，不过确实很典型啊，我还是举吧哈哈），此外还有文本情感的判别、图像识别等等应用。属于监督学习的一种。

分类问题试图将给定的某个输入数据实例划分到一些已知的类别当中，通常还是以概率的形式给出，这个概率就是输入数据属于某个类别的置信度。通常是一种多输入多输出的模型。

#### 3.2.2 回归分析

回归分析主要是用于预测某种趋势，比如用某只个股一段时间的股价来预测第二天的股价。也属于监督学习的一种。

回归分析是要从输入数据中计算出一个具体的数值，比如高中数学中教授的线性回归，通过分析大量的身高和脚长关系，可以用来根据一个人的脚长预测其身高。“回归”这个词有些生硬，可以理解为根据输入数据往一个最可能的同时也确实最符合现实规律的情况靠拢，称之为“回归”。通常是多输入单输出的模型。

#### 3.2.3 聚类问题

聚类问题中最典型的算法就是 K 均值聚类算法了。举例来讲，聚类可以用来将电商平台上的消费者按某种特征划分为各自相似的几个群落，每个群落中的消费者具有较高的相似度，因此完全可以将他们购买过的商品在群落内部频繁推荐，可以大大提高推荐的准确度。属于非监督学习。

聚类问题要的是机器从一堆数据中找到划分数据的标准，并且一开始的划分标准和稳定后的划分标准可能会存在很大的不同。

### 3.3 按确定性分类

按照机器学习算法的确定性与否，又可以将其分为**随机学习**和**确定学习**。

其中，确定学习只要给定相同的初始状态，就必然得到完全无二的结果。整个过程中没有用到随机数。

而随机学习则一定要用到随机数。这样一来，即使初始状态相同，也必然带来不同的结果；每次训练的过程虽然在大方向上是正确的，但在细节上却是完全无法掌控的。

而这两类机器学习算法中，又以随机学习的效果更好，应用更为广泛。

### 3.4 按训练批量分类

按照每次训练时的输入数据批量大小，又可以分为**在线学习**和**批量学习**两大类。

其中，在线学习指的是一次给出一个数据，机器立刻进行运算并训练。“在线”（online）二字强调的就是无时延，不迟疑，说干就干。

而批量学习则是给出若干个数据作为一个批次，记录每一个数据的实际输出，最后一个批次结束之后计算所有输出的某个统计学特性（比如平均值），以此来作为训练的依据。

我们经常看到的机器学习算法大多数都属于批量学习的范畴。究其缘由，在线学习看起来虽好，貌似有实时性，可以即时学习，但是每次训练的样本太少，很容易造成个体偏差，模型性能波动比较厉害，尤其是遇到一些极端的离群值（即与其他大多数数据差异极大的数据）时，模型很容易就烂掉了。

## 4. 总结

本文我们辨析了机器学习的一些相关概念，梳理了机器学习的一些术语，带领读者大概认识了一下“机器学习到底是个什么东西”。读者如果觉得意犹未尽，可以通过参考资料进一步学习。

后面我们还有一系列文章为大家展示“机器学习究竟可以干什么，应该怎么干”。

> 示例代码：[Python-100-days](https://github.com/JustDoPython/python-100-day/tree/master/)

## 5. 参考资料

[《机器学习》- 周志华](https://book.douban.com/subject/26708119/)

[《统计学习方法》- 李航](https://book.douban.com/subject/10590856/)

[《人工智能简史》- 尼克](https://book.douban.com/subject/27193496/)

[《人工智能算法（卷1）：基础算法》- 杰弗瑞·希顿](https://www.epubit.com/bookDetails?id=UB6ca55a7aa61e7)